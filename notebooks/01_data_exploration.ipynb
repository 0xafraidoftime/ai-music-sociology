{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI & Music Sociology: Data Exploration\n",
    "\n",
    "This notebook provides an initial exploration of music data for the AI & Music Sociology research project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_collection.spotify_scraper import SpotifyPlaylistAnalyzer\n",
    "from analysis.emotion_mapping import EmotionMapper\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for exploration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create sample playlist data\n",
    "def generate_sample_data(n_tracks=100):\n",
    "    \"\"\"Generate realistic sample music data\"\"\"\n",
    "    \n",
    "    genres = ['pop', 'rock', 'jazz', 'classical', 'electronic', 'hip_hop', 'country', 'folk']\n",
    "    artists = [f'Artist_{i}' for i in range(20)]\n",
    "    \n",
    "    data = {\n",
    "        'track_id': [f'track_{i:04d}' for i in range(n_tracks)],\n",
    "        'track_name': [f'Song Title {i}' for i in range(n_tracks)],\n",
    "        'artist_name': np.random.choice(artists, n_tracks),\n",
    "        'genre': np.random.choice(genres, n_tracks),\n",
    "        'popularity': np.random.randint(0, 100, n_tracks),\n",
    "        'duration_ms': np.random.normal(210000, 45000, n_tracks),\n",
    "        \n",
    "        # Spotify audio features\n",
    "        'valence': np.random.beta(2, 2, n_tracks),\n",
    "        'energy': np.random.beta(2, 2, n_tracks),\n",
    "        'danceability': np.random.beta(2, 2, n_tracks),\n",
    "        'acousticness': np.random.beta(2, 5, n_tracks),\n",
    "        'instrumentalness': np.random.beta(1, 10, n_tracks),\n",
    "        'liveness': np.random.beta(1, 8, n_tracks),\n",
    "        'speechiness': np.random.beta(1, 15, n_tracks),\n",
    "        'tempo': np.random.normal(120, 25, n_tracks),\n",
    "        'loudness': np.random.normal(-8, 4, n_tracks),\n",
    "        \n",
    "        # Sentiment analysis results\n",
    "        'lyric_sentiment': np.random.normal(0.1, 0.4, n_tracks),\n",
    "        'emotional_valence': np.random.normal(0.5, 0.3, n_tracks)\n",
    "    }\n",
    "    \n",
    "    # Ensure realistic ranges\n",
    "    data['duration_ms'] = np.clip(data['duration_ms'], 30000, 600000)\n",
    "    data['tempo'] = np.clip(data['tempo'], 60, 200)\n",
    "    data['loudness'] = np.clip(data['loudness'], -25, 0)\n",
    "    data['lyric_sentiment'] = np.clip(data['lyric_sentiment'], -1, 1)\n",
    "    data['emotional_valence'] = np.clip(data['emotional_valence'], 0, 1)\n",
    "    \n",
    "    for feature in ['valence', 'energy', 'danceability', 'acousticness', \n",
    "                   'instrumentalness', 'liveness', 'speechiness']:\n",
    "        data[feature] = np.clip(data[feature], 0, 1)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate and display sample data\n",
    "df = generate_sample_data(200)\n",
    "print(f\"Generated dataset with {len(df)} tracks\")\n",
    "print(f\"Features: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Number of tracks: {len(df)}\")\n",
    "print(f\"Number of unique artists: {df['artist_name'].nunique()}\")\n",
    "print(f\"Number of genres: {df['genre'].nunique()}\")\n",
    "print(f\"Average track duration: {df['duration_ms'].mean()/60000:.2f} minutes\")\n",
    "print(f\"Average popularity: {df['popularity'].mean():.2f}\")\n",
    "\n",
    "# Display basic statistics for audio features\n",
    "audio_features = ['valence', 'energy', 'danceability', 'acousticness', \n",
    "                 'instrumentalness', 'liveness', 'speechiness', 'tempo']\n",
    "\n",
    "print(\"\\nAudio Features Summary:\")\n",
    "df[audio_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Genre distribution\n",
    "genre_counts = df['genre'].value_counts()\n",
    "axes[0,0].pie(genre_counts.values, labels=genre_counts.index, autopct='%1.1f%%')\n",
    "axes[0,0].set_title('Genre Distribution')\n",
    "\n",
    "# Popularity vs Valence\n",
    "scatter = axes[0,1].scatter(df['popularity'], df['valence'], alpha=0.6, c=df['energy'], cmap='viridis')\n",
    "axes[0,1].set_xlabel('Popularity')\n",
    "axes[0,1].set_ylabel('Valence')\n",
    "axes[0,1].set_title('Popularity vs Valence (colored by Energy)')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='Energy')\n",
    "\n",
    "# Tempo distribution by genre\n",
    "df.boxplot(column='tempo', by='genre', ax=axes[1,0])\n",
    "axes[1,0].set_title('Tempo Distribution by Genre')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Audio features correlation heatmap\n",
    "corr_matrix = df[audio_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1,1])\n",
    "axes[1,1].set_title('Audio Features Correlation Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plotly visualizations\n",
    "\n",
    "# 3D scatter plot of key audio features\n",
    "fig = px.scatter_3d(\n",
    "    df, x='valence', y='energy', z='danceability',\n",
    "    color='genre', size='popularity',\n",
    "    hover_data=['track_name', 'artist_name'],\n",
    "    title='3D Audio Feature Space'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Audio features radar chart by genre\n",
    "features_for_radar = ['valence', 'energy', 'danceability', 'acousticness', 'speechiness']\n",
    "genre_means = df.groupby('genre')[features_for_radar].mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for genre in genre_means.index[:5]:  # Show top 5 genres\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=genre_means.loc[genre].values,\n",
    "        theta=features_for_radar,\n",
    "        fill='toself',\n",
    "        name=genre.capitalize()\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(visible=True, range=[0, 1])\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    title=\"Audio Features Profile by Genre\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Emotional Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform emotional clustering using KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Prepare features for clustering\n",
    "cluster_features = ['valence', 'energy', 'danceability', 'acousticness', 'lyric_sentiment']\n",
    "X = df[cluster_features].fillna(df[cluster_features].mean())\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply K-means clustering\n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df['emotion_cluster'] = clusters\n",
    "\n",
    "# Analyze clusters\n",
    "cluster_analysis = df.groupby('emotion_cluster')[cluster_features].mean()\n",
    "print(\"Cluster Centroids (average feature values):\")\n",
    "print(cluster_analysis.round(3))\n",
    "\n",
    "# Create descriptive names for clusters\n",
    "cluster_descriptions = {}\n",
    "for cluster in range(n_clusters):\n",
    "    means = cluster_analysis.loc[cluster]\n",
    "    \n",
    "    if means['valence'] > 0.6 and means['energy'] > 0.6:\n",
    "        cluster_descriptions[cluster] = \"Energetic & Positive\"\n",
    "    elif means['valence'] < 0.4 and means['energy'] < 0.4:\n",
    "        cluster_descriptions[cluster] = \"Melancholic & Calm\"\n",
    "    elif means['energy'] > 0.7:\n",
    "        cluster_descriptions[cluster] = \"High Energy\"\n",
    "    elif means['acousticness'] > 0.6:\n",
    "        cluster_descriptions[cluster] = \"Acoustic & Intimate\"\n",
    "    else:\n",
    "        cluster_descriptions[cluster] = f\"Mixed Emotions {cluster}\"\n",
    "\n",
    "df['cluster_description'] = df['emotion_cluster'].map(cluster_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters in reduced PCA space\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "df['pca1'] = X_pca[:, 0]\n",
    "df['pca2'] = X_pca[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.scatterplot(\n",
    "    data=df, x='pca1', y='pca2',\n",
    "    hue='cluster_description', palette='Set2', alpha=0.7\n",
    ")\n",
    "plt.title(\"Emotional Clusters in PCA Space\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Cluster Description\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Show sample tracks from each cluster\n",
    "for cluster, desc in cluster_descriptions.items():\n",
    "    print(f\"\\nCluster {cluster} - {desc}\")\n",
    "    display(df[df['emotion_cluster'] == cluster][['track_name', 'artist_name', 'genre']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Takeaways\n",
    "\n",
    "- The synthetic dataset captures **musical diversity** across genres, artists, and audio features.  \n",
    "- Exploratory analysis revealed **relationships between popularity, valence, and energy**, along with meaningful genre-based differences.  \n",
    "- The **clustering step grouped tracks into distinct emotional profiles** (e.g., *Energetic & Positive*, *Melancholic & Calm*).  \n",
    "- These exploratory insights provide a foundation for the **AI & Music Sociology research project**, where we can later integrate real Spotify datasets, lyrics analysis, and sociological interpretations of music consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
